{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FFNN-Application 1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhjBJgFcNVhJ",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries and Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfQJf8-0MyTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "# from torch.utils.data import DataLoader\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mbZUX2vNo_Y",
        "colab_type": "text"
      },
      "source": [
        "## Load the Dataset using Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53XJ37qrNno2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/content/diabetes.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD3RDghwa69k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For x: Extract out the dataset from all the rows (all samples and all columns except last column(all features))\n",
        "# For y: Extract out the last column(which is the label)\n",
        "# Convert both to numpy using the .values method\n",
        "\n",
        "x = data.iloc[:,0:-1].values\n",
        "y_string = list(data.iloc[:,-1])\n",
        "#y_string = data.iloc[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9WkPoY7b8Gq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our neural network only understand numbers! so convert the strings to label\n",
        "y_int = []\n",
        "for s in y_string:\n",
        "  if s == \"positive\":\n",
        "    y_int.append(1)\n",
        "  else:\n",
        "    y_int.append(0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKp0rzN0cP_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now convert to an array\n",
        "y = np.array(y_int, dtype= 'float64')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_uZDouYe5ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature normalization, All features should have the same range of values(-1, 1)\n",
        "sc = StandardScaler()\n",
        "x = sc.fit_transform(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrqFzgcJhmYY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e1aa8b0e-9572-446f-9b73-76c3ec6bee51"
      },
      "source": [
        "x"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.63994726,  0.84832379,  0.14964075, ..., -0.69289057,\n",
              "         0.20401277,  1.4259954 ],\n",
              "       [-0.84488505, -1.12339636, -0.16054575, ..., -0.69289057,\n",
              "        -0.68442195, -0.19067191],\n",
              "       [ 1.23388019,  1.94372388, -0.26394125, ..., -0.69289057,\n",
              "        -1.10325546, -0.10558415],\n",
              "       ...,\n",
              "       [ 0.3429808 ,  0.00330087,  0.14964075, ...,  0.27959377,\n",
              "        -0.73518964, -0.27575966],\n",
              "       [-0.84488505,  0.1597866 , -0.47073225, ..., -0.69289057,\n",
              "        -0.24020459,  1.17073215],\n",
              "       [-0.84488505, -0.8730192 ,  0.04624525, ..., -0.69289057,\n",
              "        -0.20212881, -0.87137393]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtpRmpuChpS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor(x)\n",
        "y = torch.tensor(y)\n",
        "y = y.unsqueeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB646iu3nTJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e4a6b26b-4636-4389-a328-430f00a0291f"
      },
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([768, 7])\n",
            "torch.Size([768, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13dfzcPvnUwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset(Dataset):\n",
        "\n",
        "  def __init__(self,x,y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhZAsOk9nWaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = Dataset(x,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7PuI59e4Z4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1bf09e71-6278-4e36-b1b5-a83e5f5abef4"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYpdGuX74cHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data to Dataloader for batch processing and shuffling\n",
        "train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o95JLF-o5Any",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7f891415-261c-413a-a9a0-d2287e19079b"
      },
      "source": [
        "# Let's have a look at the dataloader\n",
        "print(\"There is {} batch in the dataset\".format(len(train_loader)))\n",
        "for (x,y) in train_loader:\n",
        "  print(\"For one iteration or batch there is:\")\n",
        "  print(\"Data {}\".format(x.shape))\n",
        "  print(\"Labels {}\".format(y.shape))\n",
        "  break"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There is 24 batch in the dataset\n",
            "For one iteration or batch there is:\n",
            "Data torch.Size([32, 7])\n",
            "Labels torch.Size([32, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7aGCHNw5_lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's create our model\n",
        "class Model(nn.Module):\n",
        "  def __init__(self,input_features, output_features):\n",
        "    super(Model, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_features, 5)\n",
        "    self.fc2 = nn.Linear(5, 4)\n",
        "    self.fc3 = nn.Linear(4, 3)\n",
        "    self.fc4 = nn.Linear(3, output_features)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.tanh = nn.Tanh()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.tanh(out)\n",
        "    out = self.fc2(out)\n",
        "    out = self.tanh(out)\n",
        "    out = self.fc3(out)\n",
        "    out = self.tanh(out)\n",
        "    out = self.fc4(out)\n",
        "    out = self.sigmoid(out)\n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGS_13CN0mEa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7a9679ee-847c-49d1-f9aa-6cc0e046499a"
      },
      "source": [
        "# Let's create network (an object of the Model class)\n",
        "net = Model(7,1)\n",
        "#In Binary Cross Entropy: the input and output should have the same shape\n",
        "#size_average = True ----> the losses are averaged over observations for each minibatch\n",
        "\n",
        "creterion = torch.nn.BCELoss(size_average=True)\n",
        "# We wil use SGD with momentum with a learning rate of 0.1\n",
        "optimizer =  torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8Rr63wX22ID",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7281b0f9-79d2-4949-d43f-eaad8ac38e77"
      },
      "source": [
        "# Training Network\n",
        "\n",
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "  for inputs, labels in train_loader:\n",
        "    inputs = inputs.float()\n",
        "    labels = labels.float()\n",
        "    #FORWARD PROP\n",
        "    outputs = net(inputs)\n",
        "    ## outputs = net.forward(inputs, labels)\n",
        "    \n",
        "    #CALCULATE LOSS\n",
        "    loss = creterion(outputs, labels)\n",
        "    \n",
        "    #CLEAR THE GRADIENT BUFFER (w= w -lr*gradient)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #BACKWARD PROP\n",
        "    loss.backward()\n",
        "\n",
        "    #Update weights \n",
        "    optimizer.step()\n",
        "  \n",
        "  # Accuracy Calculation\n",
        "  output = (outputs>0.5).float()\n",
        "  accuracy = (output == labels).float().mean()\n",
        "  #output = (output == labels).float().sum()/ output.shape[0]\n",
        "  # Print Statistics\n",
        "  print(\"Epoch: {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(epoch+1, epochs, loss, accuracy))\n",
        "\n",
        "\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/200, Loss: 0.576, Accuracy: 0.719\n",
            "Epoch: 2/200, Loss: 0.558, Accuracy: 0.688\n",
            "Epoch: 3/200, Loss: 0.557, Accuracy: 0.719\n",
            "Epoch: 4/200, Loss: 0.517, Accuracy: 0.688\n",
            "Epoch: 5/200, Loss: 0.556, Accuracy: 0.719\n",
            "Epoch: 6/200, Loss: 0.418, Accuracy: 0.781\n",
            "Epoch: 7/200, Loss: 0.486, Accuracy: 0.812\n",
            "Epoch: 8/200, Loss: 0.477, Accuracy: 0.812\n",
            "Epoch: 9/200, Loss: 0.499, Accuracy: 0.719\n",
            "Epoch: 10/200, Loss: 0.468, Accuracy: 0.781\n",
            "Epoch: 11/200, Loss: 0.421, Accuracy: 0.812\n",
            "Epoch: 12/200, Loss: 0.406, Accuracy: 0.750\n",
            "Epoch: 13/200, Loss: 0.341, Accuracy: 0.844\n",
            "Epoch: 14/200, Loss: 0.496, Accuracy: 0.750\n",
            "Epoch: 15/200, Loss: 0.626, Accuracy: 0.656\n",
            "Epoch: 16/200, Loss: 0.311, Accuracy: 0.906\n",
            "Epoch: 17/200, Loss: 0.422, Accuracy: 0.844\n",
            "Epoch: 18/200, Loss: 0.595, Accuracy: 0.719\n",
            "Epoch: 19/200, Loss: 0.356, Accuracy: 0.844\n",
            "Epoch: 20/200, Loss: 0.482, Accuracy: 0.750\n",
            "Epoch: 21/200, Loss: 0.320, Accuracy: 0.875\n",
            "Epoch: 22/200, Loss: 0.399, Accuracy: 0.844\n",
            "Epoch: 23/200, Loss: 0.495, Accuracy: 0.719\n",
            "Epoch: 24/200, Loss: 0.619, Accuracy: 0.625\n",
            "Epoch: 25/200, Loss: 0.310, Accuracy: 0.875\n",
            "Epoch: 26/200, Loss: 0.470, Accuracy: 0.844\n",
            "Epoch: 27/200, Loss: 0.532, Accuracy: 0.719\n",
            "Epoch: 28/200, Loss: 0.611, Accuracy: 0.688\n",
            "Epoch: 29/200, Loss: 0.428, Accuracy: 0.625\n",
            "Epoch: 30/200, Loss: 0.378, Accuracy: 0.906\n",
            "Epoch: 31/200, Loss: 0.295, Accuracy: 0.875\n",
            "Epoch: 32/200, Loss: 0.472, Accuracy: 0.812\n",
            "Epoch: 33/200, Loss: 0.339, Accuracy: 0.875\n",
            "Epoch: 34/200, Loss: 0.305, Accuracy: 0.906\n",
            "Epoch: 35/200, Loss: 0.592, Accuracy: 0.625\n",
            "Epoch: 36/200, Loss: 0.328, Accuracy: 0.875\n",
            "Epoch: 37/200, Loss: 0.451, Accuracy: 0.812\n",
            "Epoch: 38/200, Loss: 0.495, Accuracy: 0.750\n",
            "Epoch: 39/200, Loss: 0.411, Accuracy: 0.844\n",
            "Epoch: 40/200, Loss: 0.390, Accuracy: 0.812\n",
            "Epoch: 41/200, Loss: 0.596, Accuracy: 0.688\n",
            "Epoch: 42/200, Loss: 0.501, Accuracy: 0.750\n",
            "Epoch: 43/200, Loss: 0.361, Accuracy: 0.844\n",
            "Epoch: 44/200, Loss: 0.355, Accuracy: 0.844\n",
            "Epoch: 45/200, Loss: 0.556, Accuracy: 0.656\n",
            "Epoch: 46/200, Loss: 0.447, Accuracy: 0.719\n",
            "Epoch: 47/200, Loss: 0.590, Accuracy: 0.625\n",
            "Epoch: 48/200, Loss: 0.505, Accuracy: 0.781\n",
            "Epoch: 49/200, Loss: 0.353, Accuracy: 0.844\n",
            "Epoch: 50/200, Loss: 0.387, Accuracy: 0.812\n",
            "Epoch: 51/200, Loss: 0.578, Accuracy: 0.656\n",
            "Epoch: 52/200, Loss: 0.401, Accuracy: 0.844\n",
            "Epoch: 53/200, Loss: 0.305, Accuracy: 0.875\n",
            "Epoch: 54/200, Loss: 0.303, Accuracy: 0.875\n",
            "Epoch: 55/200, Loss: 0.464, Accuracy: 0.625\n",
            "Epoch: 56/200, Loss: 0.492, Accuracy: 0.812\n",
            "Epoch: 57/200, Loss: 0.582, Accuracy: 0.781\n",
            "Epoch: 58/200, Loss: 0.494, Accuracy: 0.750\n",
            "Epoch: 59/200, Loss: 0.327, Accuracy: 0.875\n",
            "Epoch: 60/200, Loss: 0.654, Accuracy: 0.625\n",
            "Epoch: 61/200, Loss: 0.717, Accuracy: 0.719\n",
            "Epoch: 62/200, Loss: 0.316, Accuracy: 0.906\n",
            "Epoch: 63/200, Loss: 0.633, Accuracy: 0.656\n",
            "Epoch: 64/200, Loss: 0.331, Accuracy: 0.938\n",
            "Epoch: 65/200, Loss: 0.424, Accuracy: 0.812\n",
            "Epoch: 66/200, Loss: 0.535, Accuracy: 0.719\n",
            "Epoch: 67/200, Loss: 0.617, Accuracy: 0.625\n",
            "Epoch: 68/200, Loss: 0.294, Accuracy: 0.875\n",
            "Epoch: 69/200, Loss: 0.429, Accuracy: 0.719\n",
            "Epoch: 70/200, Loss: 0.436, Accuracy: 0.750\n",
            "Epoch: 71/200, Loss: 0.251, Accuracy: 0.875\n",
            "Epoch: 72/200, Loss: 0.353, Accuracy: 0.906\n",
            "Epoch: 73/200, Loss: 0.414, Accuracy: 0.812\n",
            "Epoch: 74/200, Loss: 0.455, Accuracy: 0.875\n",
            "Epoch: 75/200, Loss: 0.474, Accuracy: 0.781\n",
            "Epoch: 76/200, Loss: 0.287, Accuracy: 0.938\n",
            "Epoch: 77/200, Loss: 0.439, Accuracy: 0.812\n",
            "Epoch: 78/200, Loss: 0.460, Accuracy: 0.781\n",
            "Epoch: 79/200, Loss: 0.382, Accuracy: 0.812\n",
            "Epoch: 80/200, Loss: 0.677, Accuracy: 0.625\n",
            "Epoch: 81/200, Loss: 0.511, Accuracy: 0.688\n",
            "Epoch: 82/200, Loss: 0.421, Accuracy: 0.812\n",
            "Epoch: 83/200, Loss: 0.405, Accuracy: 0.719\n",
            "Epoch: 84/200, Loss: 0.394, Accuracy: 0.781\n",
            "Epoch: 85/200, Loss: 0.431, Accuracy: 0.781\n",
            "Epoch: 86/200, Loss: 0.362, Accuracy: 0.844\n",
            "Epoch: 87/200, Loss: 0.384, Accuracy: 0.750\n",
            "Epoch: 88/200, Loss: 0.494, Accuracy: 0.750\n",
            "Epoch: 89/200, Loss: 0.484, Accuracy: 0.750\n",
            "Epoch: 90/200, Loss: 0.466, Accuracy: 0.812\n",
            "Epoch: 91/200, Loss: 0.443, Accuracy: 0.750\n",
            "Epoch: 92/200, Loss: 0.327, Accuracy: 0.812\n",
            "Epoch: 93/200, Loss: 0.376, Accuracy: 0.812\n",
            "Epoch: 94/200, Loss: 0.414, Accuracy: 0.812\n",
            "Epoch: 95/200, Loss: 0.420, Accuracy: 0.906\n",
            "Epoch: 96/200, Loss: 0.337, Accuracy: 0.875\n",
            "Epoch: 97/200, Loss: 0.508, Accuracy: 0.844\n",
            "Epoch: 98/200, Loss: 0.354, Accuracy: 0.875\n",
            "Epoch: 99/200, Loss: 0.415, Accuracy: 0.812\n",
            "Epoch: 100/200, Loss: 0.335, Accuracy: 0.906\n",
            "Epoch: 101/200, Loss: 0.579, Accuracy: 0.688\n",
            "Epoch: 102/200, Loss: 0.306, Accuracy: 0.844\n",
            "Epoch: 103/200, Loss: 0.305, Accuracy: 0.906\n",
            "Epoch: 104/200, Loss: 0.267, Accuracy: 0.844\n",
            "Epoch: 105/200, Loss: 0.336, Accuracy: 0.844\n",
            "Epoch: 106/200, Loss: 0.410, Accuracy: 0.812\n",
            "Epoch: 107/200, Loss: 0.611, Accuracy: 0.656\n",
            "Epoch: 108/200, Loss: 0.401, Accuracy: 0.812\n",
            "Epoch: 109/200, Loss: 0.495, Accuracy: 0.688\n",
            "Epoch: 110/200, Loss: 0.316, Accuracy: 0.812\n",
            "Epoch: 111/200, Loss: 0.420, Accuracy: 0.781\n",
            "Epoch: 112/200, Loss: 0.218, Accuracy: 0.875\n",
            "Epoch: 113/200, Loss: 0.425, Accuracy: 0.750\n",
            "Epoch: 114/200, Loss: 0.414, Accuracy: 0.781\n",
            "Epoch: 115/200, Loss: 0.416, Accuracy: 0.812\n",
            "Epoch: 116/200, Loss: 0.543, Accuracy: 0.750\n",
            "Epoch: 117/200, Loss: 0.332, Accuracy: 0.875\n",
            "Epoch: 118/200, Loss: 0.427, Accuracy: 0.750\n",
            "Epoch: 119/200, Loss: 0.403, Accuracy: 0.844\n",
            "Epoch: 120/200, Loss: 0.382, Accuracy: 0.844\n",
            "Epoch: 121/200, Loss: 0.473, Accuracy: 0.688\n",
            "Epoch: 122/200, Loss: 0.397, Accuracy: 0.844\n",
            "Epoch: 123/200, Loss: 0.307, Accuracy: 0.844\n",
            "Epoch: 124/200, Loss: 0.818, Accuracy: 0.625\n",
            "Epoch: 125/200, Loss: 0.365, Accuracy: 0.812\n",
            "Epoch: 126/200, Loss: 0.347, Accuracy: 0.875\n",
            "Epoch: 127/200, Loss: 0.348, Accuracy: 0.812\n",
            "Epoch: 128/200, Loss: 0.427, Accuracy: 0.875\n",
            "Epoch: 129/200, Loss: 0.428, Accuracy: 0.781\n",
            "Epoch: 130/200, Loss: 0.499, Accuracy: 0.688\n",
            "Epoch: 131/200, Loss: 0.403, Accuracy: 0.844\n",
            "Epoch: 132/200, Loss: 0.294, Accuracy: 0.844\n",
            "Epoch: 133/200, Loss: 0.380, Accuracy: 0.844\n",
            "Epoch: 134/200, Loss: 0.536, Accuracy: 0.688\n",
            "Epoch: 135/200, Loss: 0.329, Accuracy: 0.812\n",
            "Epoch: 136/200, Loss: 0.287, Accuracy: 0.844\n",
            "Epoch: 137/200, Loss: 0.495, Accuracy: 0.750\n",
            "Epoch: 138/200, Loss: 0.475, Accuracy: 0.750\n",
            "Epoch: 139/200, Loss: 0.412, Accuracy: 0.844\n",
            "Epoch: 140/200, Loss: 0.260, Accuracy: 0.938\n",
            "Epoch: 141/200, Loss: 0.468, Accuracy: 0.781\n",
            "Epoch: 142/200, Loss: 0.354, Accuracy: 0.875\n",
            "Epoch: 143/200, Loss: 0.491, Accuracy: 0.719\n",
            "Epoch: 144/200, Loss: 0.490, Accuracy: 0.750\n",
            "Epoch: 145/200, Loss: 0.488, Accuracy: 0.781\n",
            "Epoch: 146/200, Loss: 0.339, Accuracy: 0.875\n",
            "Epoch: 147/200, Loss: 0.408, Accuracy: 0.781\n",
            "Epoch: 148/200, Loss: 0.477, Accuracy: 0.812\n",
            "Epoch: 149/200, Loss: 0.440, Accuracy: 0.844\n",
            "Epoch: 150/200, Loss: 0.421, Accuracy: 0.781\n",
            "Epoch: 151/200, Loss: 0.257, Accuracy: 0.938\n",
            "Epoch: 152/200, Loss: 0.322, Accuracy: 0.906\n",
            "Epoch: 153/200, Loss: 0.530, Accuracy: 0.781\n",
            "Epoch: 154/200, Loss: 0.365, Accuracy: 0.875\n",
            "Epoch: 155/200, Loss: 0.370, Accuracy: 0.844\n",
            "Epoch: 156/200, Loss: 0.252, Accuracy: 0.906\n",
            "Epoch: 157/200, Loss: 0.351, Accuracy: 0.906\n",
            "Epoch: 158/200, Loss: 0.461, Accuracy: 0.750\n",
            "Epoch: 159/200, Loss: 0.507, Accuracy: 0.719\n",
            "Epoch: 160/200, Loss: 0.449, Accuracy: 0.781\n",
            "Epoch: 161/200, Loss: 0.280, Accuracy: 0.906\n",
            "Epoch: 162/200, Loss: 0.573, Accuracy: 0.750\n",
            "Epoch: 163/200, Loss: 0.452, Accuracy: 0.812\n",
            "Epoch: 164/200, Loss: 0.407, Accuracy: 0.781\n",
            "Epoch: 165/200, Loss: 0.577, Accuracy: 0.750\n",
            "Epoch: 166/200, Loss: 0.356, Accuracy: 0.844\n",
            "Epoch: 167/200, Loss: 0.307, Accuracy: 0.875\n",
            "Epoch: 168/200, Loss: 0.365, Accuracy: 0.781\n",
            "Epoch: 169/200, Loss: 0.488, Accuracy: 0.812\n",
            "Epoch: 170/200, Loss: 0.525, Accuracy: 0.750\n",
            "Epoch: 171/200, Loss: 0.468, Accuracy: 0.781\n",
            "Epoch: 172/200, Loss: 0.353, Accuracy: 0.844\n",
            "Epoch: 173/200, Loss: 0.223, Accuracy: 0.969\n",
            "Epoch: 174/200, Loss: 0.525, Accuracy: 0.812\n",
            "Epoch: 175/200, Loss: 0.489, Accuracy: 0.750\n",
            "Epoch: 176/200, Loss: 0.471, Accuracy: 0.781\n",
            "Epoch: 177/200, Loss: 0.279, Accuracy: 0.938\n",
            "Epoch: 178/200, Loss: 0.425, Accuracy: 0.781\n",
            "Epoch: 179/200, Loss: 0.359, Accuracy: 0.875\n",
            "Epoch: 180/200, Loss: 0.268, Accuracy: 0.875\n",
            "Epoch: 181/200, Loss: 0.399, Accuracy: 0.781\n",
            "Epoch: 182/200, Loss: 0.571, Accuracy: 0.719\n",
            "Epoch: 183/200, Loss: 0.347, Accuracy: 0.844\n",
            "Epoch: 184/200, Loss: 0.439, Accuracy: 0.812\n",
            "Epoch: 185/200, Loss: 0.445, Accuracy: 0.812\n",
            "Epoch: 186/200, Loss: 0.672, Accuracy: 0.719\n",
            "Epoch: 187/200, Loss: 0.386, Accuracy: 0.812\n",
            "Epoch: 188/200, Loss: 0.330, Accuracy: 0.906\n",
            "Epoch: 189/200, Loss: 0.438, Accuracy: 0.812\n",
            "Epoch: 190/200, Loss: 0.387, Accuracy: 0.812\n",
            "Epoch: 191/200, Loss: 0.540, Accuracy: 0.688\n",
            "Epoch: 192/200, Loss: 0.503, Accuracy: 0.750\n",
            "Epoch: 193/200, Loss: 0.449, Accuracy: 0.781\n",
            "Epoch: 194/200, Loss: 0.302, Accuracy: 0.844\n",
            "Epoch: 195/200, Loss: 0.464, Accuracy: 0.812\n",
            "Epoch: 196/200, Loss: 0.510, Accuracy: 0.719\n",
            "Epoch: 197/200, Loss: 0.428, Accuracy: 0.844\n",
            "Epoch: 198/200, Loss: 0.316, Accuracy: 0.844\n",
            "Epoch: 199/200, Loss: 0.348, Accuracy: 0.875\n",
            "Epoch: 200/200, Loss: 0.461, Accuracy: 0.750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR0YQuE1_7VT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}